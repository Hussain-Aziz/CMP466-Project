{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import value_counts\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12684, 26)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12684 entries, 0 to 12683\n",
      "Data columns (total 26 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   destination           12684 non-null  object\n",
      " 1   passanger             12684 non-null  object\n",
      " 2   weather               12684 non-null  object\n",
      " 3   temperature           12684 non-null  int64 \n",
      " 4   time                  12684 non-null  object\n",
      " 5   coupon                12684 non-null  object\n",
      " 6   expiration            12684 non-null  object\n",
      " 7   gender                12684 non-null  object\n",
      " 8   age                   12684 non-null  object\n",
      " 9   maritalStatus         12684 non-null  object\n",
      " 10  has_children          12684 non-null  int64 \n",
      " 11  education             12684 non-null  object\n",
      " 12  occupation            12684 non-null  object\n",
      " 13  income                12684 non-null  object\n",
      " 14  car                   108 non-null    object\n",
      " 15  Bar                   12577 non-null  object\n",
      " 16  CoffeeHouse           12467 non-null  object\n",
      " 17  CarryAway             12533 non-null  object\n",
      " 18  RestaurantLessThan20  12554 non-null  object\n",
      " 19  Restaurant20To50      12495 non-null  object\n",
      " 20  toCoupon_GEQ5min      12684 non-null  int64 \n",
      " 21  toCoupon_GEQ15min     12684 non-null  int64 \n",
      " 22  toCoupon_GEQ25min     12684 non-null  int64 \n",
      " 23  direction_same        12684 non-null  int64 \n",
      " 24  direction_opp         12684 non-null  int64 \n",
      " 25  Y                     12684 non-null  int64 \n",
      "dtypes: int64(8), object(18)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# read csv as data frame \n",
    "df = pd.read_csv(\"coupon.csv\")\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "# gives count, mean, srd, min, 25 percentile, 50 percentile, 75 percentile, max\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num duplicates 74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "destination               0\n",
       "passanger                 0\n",
       "weather                   0\n",
       "temperature               0\n",
       "time                      0\n",
       "coupon                    0\n",
       "expiration                0\n",
       "gender                    0\n",
       "age                       0\n",
       "maritalStatus             0\n",
       "has_children              0\n",
       "education                 0\n",
       "occupation                0\n",
       "income                    0\n",
       "Bar                     107\n",
       "CoffeeHouse             217\n",
       "CarryAway               151\n",
       "RestaurantLessThan20    130\n",
       "Restaurant20To50        189\n",
       "toCoupon_GEQ5min          0\n",
       "toCoupon_GEQ15min         0\n",
       "toCoupon_GEQ25min         0\n",
       "direction_same            0\n",
       "Y                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop cars as it is mostly blank (108 are blank, 12576 are empty)\n",
    "df = df.drop(columns=['car'])\n",
    "\n",
    "# drop direction_opp as it is inverse of direction_same so its redundant\n",
    "df = df.drop(columns=['direction_opp'])\n",
    "\n",
    "# print number of duplicates\n",
    "print(\"num duplicates\", df.duplicated().sum())\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blanks and Duplicates\n",
    "|column|number of blanks|most common class|\n",
    "|------|----------------|-----------------|\n",
    "|bar|107|never (5k)|\n",
    "|CoffeeHouse|217|less1 (3.3k), 1~3 (3.2k)|\n",
    "|CarryAway|151|1~3 (4.6k), 4~8 (4.3k)|\n",
    "|RestaurantLessThan20|130|1~3(5.3k), 4~8 (3.5k)|\n",
    "|Restaurant20To50|189|1~3 (5.3k), 4~8 (3.5k)|\n",
    "\n",
    "### Other observations\n",
    "- There are 72 duplicates\n",
    "- There 42 common blanks between these 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "destination               0\n",
       "passanger                 0\n",
       "weather                   0\n",
       "temperature               0\n",
       "time                      0\n",
       "coupon                    0\n",
       "expiration                0\n",
       "gender                    0\n",
       "age                       0\n",
       "maritalStatus             0\n",
       "has_children              0\n",
       "education                 0\n",
       "occupation                0\n",
       "income                    0\n",
       "Bar                      65\n",
       "CoffeeHouse             175\n",
       "CarryAway               108\n",
       "RestaurantLessThan20     87\n",
       "Restaurant20To50        147\n",
       "toCoupon_GEQ5min          0\n",
       "toCoupon_GEQ15min         0\n",
       "toCoupon_GEQ25min         0\n",
       "direction_same            0\n",
       "Y                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# list of columns with blank values\n",
    "blank_columns = ['Bar', 'CoffeeHouse', 'CarryAway', 'RestaurantLessThan20', 'Restaurant20To50']\n",
    "\n",
    "# delete 42 common null values\n",
    "df.dropna(subset=blank_columns, how='all', inplace=True)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "destination             0\n",
       "passanger               0\n",
       "weather                 0\n",
       "temperature             0\n",
       "time                    0\n",
       "coupon                  0\n",
       "expiration              0\n",
       "gender                  0\n",
       "age                     0\n",
       "maritalStatus           0\n",
       "has_children            0\n",
       "education               0\n",
       "occupation              0\n",
       "income                  0\n",
       "Bar                     0\n",
       "CoffeeHouse             0\n",
       "CarryAway               0\n",
       "RestaurantLessThan20    0\n",
       "Restaurant20To50        0\n",
       "toCoupon_GEQ5min        0\n",
       "toCoupon_GEQ15min       0\n",
       "toCoupon_GEQ25min       0\n",
       "direction_same          0\n",
       "Y                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null impute based on weighted average of values ub rgar column\n",
    "for column in blank_columns:\n",
    "    weights = df[column].value_counts(normalize=True)\n",
    "    df[column].fillna(pd.Series(np.random.choice(weights.index, size=len(df.index), p=weights.values.tolist())), inplace=True)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding\n",
    "| Column Name | Data Type |\n",
    "|-------------|-----------|\n",
    "| destination | nominal   |\n",
    "| passanger   | nominal   |\n",
    "| weather     | nominal   |\n",
    "| temperature | ordinal   |\n",
    "| time        | ordinal   |\n",
    "| coupon      | nominal   |\n",
    "| expiration  | ordinal   |\n",
    "| gender      | nominal   |\n",
    "| age         | ordinal   |\n",
    "| maritalStatus | nominal |\n",
    "| has_children | encoded  |\n",
    "| education   | ordinal   |\n",
    "| occupation  | nominal   |\n",
    "| income      | ordinal   |\n",
    "| Bar         | ordinal   |\n",
    "| CoffeeHouse | ordinal   |\n",
    "| CarryAway   | ordinal   |\n",
    "| RestaurantLessThan20 | ordinal |\n",
    "| Restaurant20To50 | ordinal |\n",
    "| toCoupon_GEQ5min | encoded |\n",
    "| toCoupon_GEQ15min | encoded |\n",
    "| toCoupon_GEQ25min | encoded |\n",
    "| direction_opp | encoded  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Encoding\n",
    "\n",
    "# a common classes order for all some columns\n",
    "amount_visited_order = ['never','less1','1~3','4~8','gt8']\n",
    "\n",
    "# ordinal columns with their categories in order\n",
    "ordinal_columns = [('temperature',['30','55','80']), \n",
    "                   ('time', ['7AM', '10AM', '2PM', '6PM', '10PM']), \n",
    "                   ('expiration', ['2h', '1d']),\n",
    "                   ('gender', ['Male', 'Female']), # since its 2 values we can do ordinal encoding\n",
    "                   ('age', ['below21','21','26','31','36','41','46','50plus']), \n",
    "                   ('education', ['Some High School', 'High School Graduate', 'Some college - no degree', 'Associates degree', 'Bachelors degree', 'Graduate degree (Masters or Doctorate)']),\n",
    "                   ('income', ['Less than $12500','$12500 - $24999','$25000 - $37499','$37500 - $49999','$50000 - $62499','$62500 - $74999','$75000 - $87499','$87500 - $99999','$100000 or More']),\n",
    "                   ('Bar', amount_visited_order),\n",
    "                   ('CoffeeHouse', amount_visited_order),\n",
    "                   ('CarryAway', amount_visited_order),\n",
    "                   ('RestaurantLessThan20', amount_visited_order),\n",
    "                   ('Restaurant20To50', amount_visited_order)]\n",
    "\n",
    "# apply the ordinal encoding\n",
    "for column, categories in ordinal_columns:\n",
    "    df[column] =  OrdinalEncoder(categories=[categories]).fit_transform(df[[column]])\n",
    "\n",
    "# to check if it worked\n",
    "# df.to_csv('coupon_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unemployed                                   1849\n",
       "Student                                      1575\n",
       "Computer & Mathematical                      1372\n",
       "Sales & Related                              1088\n",
       "Education&Training&Library                    939\n",
       "Management                                    815\n",
       "Office & Administrative Support               638\n",
       "Arts Design Entertainment Sports & Media      627\n",
       "Business & Financial                          537\n",
       "Retired                                       493\n",
       "Food Preparation & Serving Related            298\n",
       "Healthcare Practitioners & Technical          244\n",
       "Healthcare Support                            242\n",
       "Community & Social Services                   239\n",
       "Legal                                         219\n",
       "Transportation & Material Moving              218\n",
       "Architecture & Engineering                    175\n",
       "Personal Care & Service                       175\n",
       "Protective Service                            174\n",
       "Life Physical Social Science                  169\n",
       "Construction & Extraction                     154\n",
       "Installation Maintenance & Repair             133\n",
       "Production Occupations                        108\n",
       "Building & Grounds Cleaning & Maintenance      44\n",
       "Farming Fishing & Forestry                     43\n",
       "Name: occupation, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nominal Encoding\n",
    "\n",
    "nomimal_columns = ['destination', 'passanger', 'weather', 'coupon', 'maritalStatus', 'occupation']\n",
    "\n",
    "for column in nomimal_columns:\n",
    "    df = pd.get_dummies(df, columns=[column]) # type: ignore\n",
    "\n",
    "# to check if it worked\n",
    "# df.to_csv('coupon_processed_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12568 entries, 0 to 12683\n",
      "Data columns (total 63 columns):\n",
      " #   Column                                                Non-Null Count  Dtype  \n",
      "---  ------                                                --------------  -----  \n",
      " 0   temperature                                           12568 non-null  float64\n",
      " 1   time                                                  12568 non-null  float64\n",
      " 2   expiration                                            12568 non-null  float64\n",
      " 3   gender                                                12568 non-null  float64\n",
      " 4   age                                                   12568 non-null  float64\n",
      " 5   has_children                                          12568 non-null  int64  \n",
      " 6   education                                             12568 non-null  float64\n",
      " 7   income                                                12568 non-null  float64\n",
      " 8   Bar                                                   12568 non-null  float64\n",
      " 9   CoffeeHouse                                           12568 non-null  float64\n",
      " 10  CarryAway                                             12568 non-null  float64\n",
      " 11  RestaurantLessThan20                                  12568 non-null  float64\n",
      " 12  Restaurant20To50                                      12568 non-null  float64\n",
      " 13  toCoupon_GEQ5min                                      12568 non-null  int64  \n",
      " 14  toCoupon_GEQ15min                                     12568 non-null  int64  \n",
      " 15  toCoupon_GEQ25min                                     12568 non-null  int64  \n",
      " 16  direction_same                                        12568 non-null  int64  \n",
      " 17  Y                                                     12568 non-null  int64  \n",
      " 18  destination_Home                                      12568 non-null  uint8  \n",
      " 19  destination_No Urgent Place                           12568 non-null  uint8  \n",
      " 20  destination_Work                                      12568 non-null  uint8  \n",
      " 21  passanger_Alone                                       12568 non-null  uint8  \n",
      " 22  passanger_Friend(s)                                   12568 non-null  uint8  \n",
      " 23  passanger_Kid(s)                                      12568 non-null  uint8  \n",
      " 24  passanger_Partner                                     12568 non-null  uint8  \n",
      " 25  weather_Rainy                                         12568 non-null  uint8  \n",
      " 26  weather_Snowy                                         12568 non-null  uint8  \n",
      " 27  weather_Sunny                                         12568 non-null  uint8  \n",
      " 28  coupon_Bar                                            12568 non-null  uint8  \n",
      " 29  coupon_Carry out & Take away                          12568 non-null  uint8  \n",
      " 30  coupon_Coffee House                                   12568 non-null  uint8  \n",
      " 31  coupon_Restaurant(20-50)                              12568 non-null  uint8  \n",
      " 32  coupon_Restaurant(<20)                                12568 non-null  uint8  \n",
      " 33  maritalStatus_Divorced                                12568 non-null  uint8  \n",
      " 34  maritalStatus_Married partner                         12568 non-null  uint8  \n",
      " 35  maritalStatus_Single                                  12568 non-null  uint8  \n",
      " 36  maritalStatus_Unmarried partner                       12568 non-null  uint8  \n",
      " 37  maritalStatus_Widowed                                 12568 non-null  uint8  \n",
      " 38  occupation_Architecture & Engineering                 12568 non-null  uint8  \n",
      " 39  occupation_Arts Design Entertainment Sports & Media   12568 non-null  uint8  \n",
      " 40  occupation_Building & Grounds Cleaning & Maintenance  12568 non-null  uint8  \n",
      " 41  occupation_Business & Financial                       12568 non-null  uint8  \n",
      " 42  occupation_Community & Social Services                12568 non-null  uint8  \n",
      " 43  occupation_Computer & Mathematical                    12568 non-null  uint8  \n",
      " 44  occupation_Construction & Extraction                  12568 non-null  uint8  \n",
      " 45  occupation_Education&Training&Library                 12568 non-null  uint8  \n",
      " 46  occupation_Farming Fishing & Forestry                 12568 non-null  uint8  \n",
      " 47  occupation_Food Preparation & Serving Related         12568 non-null  uint8  \n",
      " 48  occupation_Healthcare Practitioners & Technical       12568 non-null  uint8  \n",
      " 49  occupation_Healthcare Support                         12568 non-null  uint8  \n",
      " 50  occupation_Installation Maintenance & Repair          12568 non-null  uint8  \n",
      " 51  occupation_Legal                                      12568 non-null  uint8  \n",
      " 52  occupation_Life Physical Social Science               12568 non-null  uint8  \n",
      " 53  occupation_Management                                 12568 non-null  uint8  \n",
      " 54  occupation_Office & Administrative Support            12568 non-null  uint8  \n",
      " 55  occupation_Personal Care & Service                    12568 non-null  uint8  \n",
      " 56  occupation_Production Occupations                     12568 non-null  uint8  \n",
      " 57  occupation_Protective Service                         12568 non-null  uint8  \n",
      " 58  occupation_Retired                                    12568 non-null  uint8  \n",
      " 59  occupation_Sales & Related                            12568 non-null  uint8  \n",
      " 60  occupation_Student                                    12568 non-null  uint8  \n",
      " 61  occupation_Transportation & Material Moving           12568 non-null  uint8  \n",
      " 62  occupation_Unemployed                                 12568 non-null  uint8  \n",
      "dtypes: float64(12), int64(6), uint8(45)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems:\n",
    "- occupation with OHE causes too many columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for machine learning, we need arrays so we extract y as array\n",
    "y = df[\"Y\"].to_numpy()\n",
    "\n",
    "# drop the target column\n",
    "df = df.drop(columns=[\"Y\"]) \n",
    "\n",
    "# extract x as array\n",
    "x = df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy 0.9988064451959419\n",
      "testing accuracy 0.6813842482100239\n",
      "node count 5275\n",
      "depth 26\n",
      "number of leaves 2638\n"
     ]
    }
   ],
   "source": [
    "# split into training and testing\n",
    "x_train, x_test, y_train, y_test, = train_test_split(x,y, test_size=0.2)\n",
    "\n",
    "# Create classifier decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create decision tree classifer object\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "# train decision tree classifer\n",
    "dtc.fit(x_train, y_train)\n",
    "\n",
    "# predict the response for test dataset\n",
    "y_predicted = dtc.predict(x_test)\n",
    "\n",
    "# check accuracy\n",
    "print(f\"training accuracy {dtc.score(x_train, y_train)}\")\n",
    "print(f\"testing accuracy {dtc.score(x_test, y_test)}\")\n",
    "\n",
    "print(f\"node count {dtc.tree_.node_count}\")\n",
    "print(f\"depth {dtc.get_depth()}\")\n",
    "print(f\"number of leaves {dtc.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune\n",
    "\n",
    "def tune(start, stop, step, dtc, x, y):\n",
    "    data = []\n",
    "    current_percent = 10\n",
    "    start_time = time.time()\n",
    "    for i in range(start, stop, step):\n",
    "        node_count = []\n",
    "        testing_accuracy = []\n",
    "        training_accuracy = []\n",
    "        for _ in range(50):\n",
    "            \n",
    "            # create decision tree classifer object\n",
    "            dtc_tune = dtc(i)\n",
    "\n",
    "            # split data\n",
    "            x_train, x_test, y_train, y_test, = train_test_split(x,y, test_size=0.2)\n",
    "\n",
    "            # train decision tree classifer\n",
    "            dtc_tune.fit(x_train, y_train)\n",
    "\n",
    "            # get traning and testing accuracy\n",
    "            node_count.append(dtc_tune.tree_.node_count)\n",
    "            training_accuracy.append(dtc_tune.score(x_train, y_train))\n",
    "            testing_accuracy.append(dtc_tune.score(x_test, y_test))\n",
    "\n",
    "        \n",
    "        # get average of 50 runs\n",
    "        node_count = sum(node_count) / len(node_count)\n",
    "        training_accuracy = sum(training_accuracy) / len(training_accuracy)\n",
    "        testing_accuracy = sum(testing_accuracy) / len(testing_accuracy)\n",
    "\n",
    "        data.append([node_count, training_accuracy, testing_accuracy])\n",
    "\n",
    "        if (i - start) // step > ((stop - start) // step + 1) * current_percent/100:\n",
    "            print(f\"{current_percent}% done at {(time.time()-start_time)/60} minutes\")\n",
    "            current_percent += 10\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def plot(data, title):\n",
    "        # convert data to data frame\n",
    "    df = pd.DataFrame(data, columns=[\"node_count\", \"training_accuracy\", \"testing_accuracy\"])\n",
    "\n",
    "    # plot node count vs training accuracy and testing accuracy and label the graph\n",
    "    df.plot(x=\"node_count\", y=[\"training_accuracy\", \"testing_accuracy\"])\n",
    "    plt.xlabel(\"node count\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% done at 3.299119504292806 minutes\n",
      "20% done at 5.610114181041718 minutes\n",
      "30% done at 8.827525556087494 minutes\n",
      "40% done at 10.698523497581482 minutes\n",
      "50% done at 12.435900684197744 minutes\n",
      "60% done at 14.392653294404347 minutes\n"
     ]
    }
   ],
   "source": [
    "# min sample split\n",
    "min_sample_split = tune(2, 2000, 5, lambda i: DecisionTreeClassifier(min_samples_split=i), x, y)\n",
    "plot(min_sample_split, \"min sample split\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion{“gini”, “entropy”, “log_loss”}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitter{“best”, “random”}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth\n",
    "# with default params: 41\n",
    "max_depth = tune(1, 40, 1, lambda i: DecisionTreeClassifier(max_depth=i), x, y)\n",
    "plot(max_depth, \"max depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_leaf \n",
    "# The minimum number of samples required to split an internal node:\n",
    "min_samples_leaf = tune(2, 1000, 5, lambda i: DecisionTreeClassifier(min_samples_leaf=i), x, y)\n",
    "plot(min_samples_leaf, \"min samples leaf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_weight_fraction_leaf\n",
    "# The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. \n",
    "# Samples have equal weight when sample_weight is not provided.\n",
    "\n",
    "min_weight_fraction_leaf = tune(0.0, 1.0, 0.05, lambda i: DecisionTreeClassifier(min_weight_fraction_leaf=i), x, y)\n",
    "plot(min_weight_fraction_leaf, \"min_weight_fraction_leaf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_features int, float or {“auto”, “sqrt”, “log2”},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_leaf_nodes\n",
    "# with default params: 2716\n",
    "\n",
    "max_leaf_nodes = tune(0.0, 1.0, 0.05, lambda i: DecisionTreeClassifier(max_leaf_nodes=i), x, y)\n",
    "plot(max_leaf_nodes, \"max_leaf_nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing\n",
    "x_train, x_test, y_train, y_test, = train_test_split(x,y, test_size=0.2)\n",
    "\n",
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# create KNN classifer object\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# train decision tree classifer\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "# predict the response for test dataset\n",
    "y_predicted = knn.predict(x_test)\n",
    "\n",
    "# check accuracy\n",
    "print(f\"training accuracy {knn.score(x_train, y_train)}\")\n",
    "print(f\"testing accuracy {knn.score(x_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test, = train_test_split(x,y, test_size=0.2)\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# create KNN classifer object\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# train decision tree classifer\n",
    "gnb.fit(x_train, y_train)\n",
    "\n",
    "# predict the response for test dataset\n",
    "y_predicted = gnb.predict(x_test)\n",
    "\n",
    "# check accuracy\n",
    "print(f\"training accuracy {gnb.score(x_train, y_train)}\")\n",
    "print(f\"testing accuracy {gnb.score(x_test, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
